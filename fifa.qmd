---
title: "The FIFA World Cup"
subtitle: "A recreation of Tanya Shapiro's Dataviz"

author: 
- name: "Matthew Kuch"
  email: kuch.matthew@gmail.com
date: 11/23/2024

title-block-banner: "#f0f3f5"
title-block-banner-color: "black"

format: html
html:
code-fold: true
code-summary: "Code"
css: style.css
toc: true
toc-location: left
number-sections: true
editor: visual
fig-cap-location: margin
---

This breadcrumb/tutorial will walk you through in detail how to recreate Tanya Shapiro's visualization below.

**I hope you enjoy this because at each stage of recreating this dataviz is like solving a puzzle!**

![The goal is to recreate this](./assets/fifa.png)

We're going to re-engineer the above dataviz in 6 steps:

1.  Load the required libraries
2.  Setup the nice looking fonts
3.  Webscraping wikipedia (for the FIFA world cup data)
4.  Data wrangling and transformation (final step before visualization)
5.  Create the heatmap and polish it
6.  Add text and annotations

# Load the required libraries

To accomplish the 7 steps above, the libraries that will help us are below :

i.  **Data manipulation and visualization**: tidyverse, RColorBrewer, viridis

ii. **Fonts and text customization**: sysfonts, showtext

iii. **Specialized ggplot features**: geomtextpath, ggimage, ggtext

iv. **Webscraping:** rvest

```{r warning=FALSE, message=FALSE}

library(tidyverse)
library(RColorBrewer)
library(viridis)
library(sysfonts)
library(showtext)
library(geomtextpath)
library(ggimage)
library(ggtext)
library(rvest)

```

# Setup the nice looking fonts

The custom fonts we'll use for different parts of the visualization are as follows:

-   The main text font is **Roboto** (downloaded via Google Fonts).

-   The title font is **Cocon**, which resembles FIFA branding.

-   The caption uses **Font Awesome** for social media icons.

```{r}

sysfonts::font_add_google("Roboto", "Roboto")
sysfonts::font_add("Cocon", "./fonts/CoconRegularFont.otf")
sysfonts::font_add("fb", "fonts/Font Awesome 6 Brands-Regular-400.otf")
showtext_auto()
showtext::showtext_opts(dpi = 300)

```

# Webscraping wikipedia (for the FIFA world cup data)

Now to the fun stuff, lets retrieve FIFA World Cup data from Wikipedia, using the rvest package for web scraping. The goal is to extract relevant tables from the Wikipedia pages for each tournament year.

![URL for 1982 FIFA World Cup](assets/fifa-wiki-1982-url.jpg){fig-align="center"}

## Setting up a reference table

The reference table (`ref`) contains the following:

-   **`year`**: The years of the FIFA World Cup (1982â€“2018 in this example).

-   **`index`**: The position of the table on each year's Wikipedia page.

-   **`host`**: The country that hosted the tournament in each year.

-   **`link`**: The URL to the Wikipedia page for each year's tournament.

```{r}

ref = data.frame(
    year = c(1982, 1986, 1990, 1994, 1998, 2002, 2006, 2010, 2014),
    index = c(16, 14, 15, 13, 25, 24, 23, 14, 20),
    host = c("Spain", "Mexico", "Italy", "United States", "France",
             "South Korea", "Germany", "South Africa", "Brazil")
)

# Generate links to all Wikipedia pages for these years
ref$link = paste0("https://en.wikipedia.org/wiki/", ref$year, "_FIFA_World_Cup")

```

This ref table acts as a roadmap for the scraping function, specifying the exact URL and table position for each year.

## Lets first get 1 table for 1982, as a test case

To test our web-scraping logic, lets first scrape the 1982 table:

```{r}

# Step 1: Get the URL and table index for the year 1982
  url = ref$link[ref$year == 1982]
  index = ref$index[ref$year == 1982]
  
  # Step 2: Scrape the table from the Wikipedia page
  data = url %>%
    read_html() %>%                    # Read the HTML content of the page
    html_elements("table.wikitable") %>%  # Select all tables with the 'wikitable' class
    .[index] %>%                       # Pick the table based on the given index
    html_table() %>%                   # Convert the table to a dataframe
    .[[1]]                             # Extract the first element of the list

  
# Step 3: Clean and format the table
  data = data %>%
    rename(Pos = 1) %>%                # Rename the first column to 'Pos' (Position)
    select(Pos, Team, L, W)            # Keep only Position, Team, Losses, and Wins columns
  
```

## Helper Function: `get_table()`

The function `get_table(year)` will perform the following steps:

-   Retrieves the appropriate URL and table index for a given `year`.

-   Scrapes the specified table from the Wikipedia page.

-   Renames and selects the required columns: **Position (`Pos`)**, **Team**, **Losses (`L`)**, and **Wins (`W`)**.

-   Adds the `year` column to identify the tournament.

```{r}

get_table <- function(year) {
  # Step 1: Get the URL and table index for the year
  url = ref$link[ref$year == year]
  index = ref$index[ref$year == year]
  
  # Step 2: Scrape the table from the Wikipedia page
  data = url %>%
    read_html() %>%                    # Read the HTML content of the page
    html_elements("table.wikitable") %>%  # Select all tables with the 'wikitable' class
    .[index] %>%                       # Pick the table based on the given index
    html_table() %>%                   # Convert the table to a dataframe
    .[[1]]                             # Extract the first element of the list
  
  # Step 3: Clean and format the table
  data = data %>%
    rename(Pos = 1) %>%                # Rename the first column to 'Pos' (Position)
    select(Pos, Team, L, W)            # Keep only Position, Team, Losses, and Wins columns
  
  # Step 4: Add the year column
  data$year = year
  
  return(data)
}

```

**Explanation of key steps**:

-   **Scraping with `read_html` and `html_elements`:** Reads the webpage and selects all tables with the `wikitable` CSS class (a standard for tables on Wikipedia).

-   **Indexing with `.[index]`:** Extracts the specific table based on the `index` column in the `ref` table.

-   **Converting the table with `html_table`:** Converts the HTML table into a tidy dataframe.

-   **Column selection and renaming:** Cleans the scraped table by renaming and selecting only the required columns.

## Loop through all the years

The script below loops through all years in `ref$year`, applying `get_table()` to each year. The results are combined into a single dataframe (`data`).

```{r}
# Initialize an empty dataframe
data = data.frame()

# Loop through each year and scrape the corresponding data
for (i in ref$year) {
  data = rbind(data, get_table(i))
}

# Remove unwanted rows 
data <- data[!grepl("Eliminated in the", data$Pos),] %>% na.omit()  

```

## Post scraping data cleaning

### **Standardize Team Names**:

-   West Germany is relabeled as Germany for consistency.

```{r}
data <- data %>%
  mutate(Team = case_when(Team == "West Germany" ~ "Germany", TRUE ~ Team))

```

### **Filter Frequent Participants**:

-   Only keep teams that participated in at least 4 tournaments.

```{r}
teams <- data %>%
  group_by(Team) %>%
  summarise(wc = n()) %>%
  filter(wc > 3)

```

**Purpose**:

-   This ensures the visualization focuses on teams with a significant history in the World Cup

### Group by geographic region

```{r}

geo_group <- data.frame(
  country = c("Italy","Germany","England","Norway","Sweden","Switzerland","Netherlands","France","Belgium",
              "Spain","Croatia","Poland","Portugal","Denmark","Russia","Scotland",
              "United States","Argentina","Brazil","Paraguay","Uruguay","Costa Rica","Colombia","Chile","Mexico",
              "Nigeria","Cameroon","Saudi Arabia","South Korea","Japan","Iran","Morocco","Algeria"
  ),
  geo = c(rep("Europe",16), rep("Americas",9), rep("Other",8))
)

#Create Factor for Continent to arrange in order
geo_group$geo<-factor(geo_group$geo, levels=c("Europe","Americas","Other"))


```

The `geo_group` dataframe is created to group the countries (teams) into geographic regions (e.g., Europe, Americas, Other). These groupings will later be used to:

1.  **Color-code** teams by region.

2.  **Create section labels in the visualization** (e.g., "Europe", "Americas", "Other").

# Data wrangling and transformation

## Prepare the data for plotting

```{r}

df_plot <- data %>%
  filter(!grepl("Eliminated", Pos) & Team %in% teams$Team) %>%
  left_join(teams, by = "Team") %>%
  left_join(geo_group, by = c("Team" = "country")) %>%
  left_join(ref, by = "year") %>%
  group_by(year) %>%
  complete(Team = teams$Team) %>%
  filter(!grepl("Eliminated", Team)) %>%
  mutate(counter = 1,
         Pos = as.integer(Pos),
         group = case_when(
           is.na(Pos) ~ "Not Present",
           Pos == 1 ~ "Win",
           Pos <= 4 ~ "Semi Finals",
           Pos <= 8 ~ "Quarter Finals",
           Pos <= 16 ~ "Round of 16",
           Pos <= 32 ~ "Group Stage"
         )) %>%
  ungroup() %>%
  group_by(Team) %>%
  arrange(Team, year) %>%
  mutate(wc = sum(counter[group != "Not Present"]),
         win = sum(counter[group == "Win"])) %>%
  arrange(geo, -wc, -win, Team) %>%
  ungroup()

```

### Detailed explanation of the above code snippet for df_plot

#### Filter Relevant Data

```{r}

# filter(!grepl("Eliminated", Pos) & Team %in% teams$Team)

```

**Purpose**: Exclude irrelevant rows from the data.

-   `!grepl("Eliminated", Pos)`: Removes rows where the position (`Pos`) contains the word "Eliminated".

-   `Team %in% teams$Team`: Keeps only teams that participated in more than 3 tournaments (filtered earlier in `teams`).

#### Join Additional Data

```{r}

# left_join(teams, by = "Team") %>%
# left_join(geo_group, by = c("Team" = "country")) %>%
# left_join(ref, by = "year")

```

**Purpose**: Merge additional information into the main dataframe.

-   `teams`: Adds the number of World Cups each team participated in (`wc`).

-   `geo_group`: Adds geographic groupings (e.g., Europe, Americas).

-   `ref`: Adds metadata like the tournament's host country and year.

#### Group and Ensure All Teams Appear Each Year
